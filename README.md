# ATLAS_Project
<h1 align="center">
  <br>
   <img src="https://github.com/Satyam-kumar-yadav/ATLAS_Project/blob/main/assets/atlas.jpg" alt="Logo ArrayMixer" />
  <br>
</h1>
<p align="center">  
<a href="https://www.codacy.com/app/josetelesmaciel/array-mixer?utm_source=github.com&utm_medium=referral&utm_content=teles/array-mixer&utm_campaign=badger"><img src="https://api.codacy.com/project/badge/Grade/2cbd62dd3c284ce79f6e2c35817bec12"></a>
<a href="https://www.codacy.com/app/josetelesmaciel/array-mixer?utm_source=github.com&utm_medium=referral&utm_content=teles/array-mixer&utm_campaign=Badge_Coverage"><img src="https://api.codacy.com/project/badge/Coverage/8a941e0f57c047c8a481f4854666b42d"></a>
 <a href="https://opensource.org/licenses/apache-2.0"><img src="https://img.shields.io/badge/license-apache2.0-blue.svg"></a>
</p>

## About The Project
Deep compression refers to the usage of autoencoders for performing data compression.
The aim is to learn the data distribution by projecting it to a lower-dimension and then
reprojecting. The project’s idea is to use deep compression for HEP data and check their
efficacy. Therefore, the objective while learning the neural network is to maintain the
data’s fidelity after performing compression and decompression.

```
For Data Extraction - data.py
For Training the model - 4D-TLA.ipynb
For Plots - assets
```
